{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSTdf2HtAtpm3xz86Nw14T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keravraj20/ds1/blob/master/cnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4U1dlZdPjxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87fbfd40-505e-49ff-e169-d9aa6c601eb5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpwaFEybC6_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d6f7d5d-986a-480c-dd40-acf8e915fa44"
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# update 1\n",
        "!conda install -q -y --prefix /usr/local python=3.6 ujson\n",
        "# update 2\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "# test it\n",
        "import ujson\n",
        "print(ujson.dumps({1:2}))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-16 13:13:37--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-4.5.4-Li 100%[===================>]  55.76M   144MB/s    in 0.4s    \n",
            "\n",
            "2020-09-16 13:13:37 (144 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - python=3.6\n",
            "    - ujson\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    sqlite-3.33.0              |       h62c20be_0         2.0 MB\n",
            "    readline-8.0               |       h7b6447c_0         428 KB\n",
            "    python-3.6.12              |       hcff3b4d_2        34.0 MB\n",
            "    wheel-0.35.1               |             py_0          36 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         645 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         3.8 MB\n",
            "    setuptools-49.6.0          |           py36_0         927 KB\n",
            "    ujson-3.1.0                |   py36he6710b0_0          50 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    pip-20.2.2                 |           py36_0         2.0 MB\n",
            "    certifi-2020.6.20          |           py36_0         160 KB\n",
            "    ca-certificates-2020.7.22  |                0         132 KB\n",
            "    libedit-3.1.20191231       |       h14c3975_1         121 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        61.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:    0.1-main               \n",
            "    ld_impl_linux-64: 2.33.1-h53a641e_7      \n",
            "    ujson:            3.1.0-py36he6710b0_0   \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:  2018.03.07-0            --> 2020.7.22-0            \n",
            "    certifi:          2018.4.16-py36_0        --> 2020.6.20-py36_0       \n",
            "    libedit:          3.1.20170329-h6b74fdf_2 --> 3.1.20191231-h14c3975_1\n",
            "    libffi:           3.2.1-hd88cf55_4        --> 3.3-he6710b0_2         \n",
            "    libgcc-ng:        7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    libstdcxx-ng:     7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    ncurses:          6.1-hf484d3e_0          --> 6.2-he6710b0_1         \n",
            "    openssl:          1.0.2o-h20670df_0       --> 1.1.1g-h7b6447c_0      \n",
            "    pip:              10.0.1-py36_0           --> 20.2.2-py36_0          \n",
            "    python:           3.6.5-hc3d631a_2        --> 3.6.12-hcff3b4d_2      \n",
            "    readline:         7.0-ha6073c6_4          --> 8.0-h7b6447c_0         \n",
            "    setuptools:       39.2.0-py36_0           --> 49.6.0-py36_0          \n",
            "    sqlite:           3.23.1-he433501_0       --> 3.33.0-h62c20be_0      \n",
            "    tk:               8.6.7-hc745277_3        --> 8.6.10-hbc83047_0      \n",
            "    wheel:            0.31.1-py36_0           --> 0.35.1-py_0            \n",
            "    xz:               5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0       \n",
            "    zlib:             1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3      \n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "{\"1\":2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ELtdeTnEfua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/ExtremeNet/conda_packagelist.txt\" \"/content/drive/My Drive/pd\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWJ-vQ0Duja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed9fc374-6c55-4b3a-c34f-1bc69ef2f923"
      },
      "source": [
        "!conda create --name centernet --file \"/content/drive/My Drive/pd/conda_packagelist.txt\"\n",
        "!source activate centernet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and Extracting Packages\n",
            "blas-1.0             |         | : 100% 1.0/1 [00:00<00:00,  3.67it/s] \n",
            "bzip2-1.0.6          |         | : 100% 1.0/1 [00:00<00:00,  5.46it/s]               \n",
            "ca-certificates-2018 |         | : 100% 1.0/1 [00:00<00:00,  5.34it/s]                \n",
            "caffe2-cuda8.0-cudnn |         | : 100% 1.0/1 [00:07<00:00,  7.94s/it]               \n",
            "cairo-1.14.12        |         | : 100% 1.0/1 [00:00<00:00,  2.36it/s]               \n",
            "certifi-2018.4.16    |         | : 100% 1.0/1 [00:00<00:00, 11.07it/s]\n",
            "cffi-1.11.5          |         | : 100% 1.0/1 [00:00<00:00,  7.93it/s]\n",
            "cudatoolkit-8.0      |         | : 100% 1.0/1 [00:47<00:00, 47.17s/it]                \n",
            "cycler-0.10.0        |         | : 100% 1.0/1 [00:00<00:00, 14.25it/s]\n",
            "dbus-1.13.2          |         | : 100% 1.0/1 [00:00<00:00,  5.61it/s]               \n",
            "expat-2.2.5          |         | : 100% 1.0/1 [00:00<00:00,  8.89it/s]\n",
            "ffmpeg-3.4           |         | : 100% 1.0/1 [00:01<00:00,  1.54s/it]               \n",
            "fontconfig-2.12.6    |         | : 100% 1.0/1 [00:00<00:00,  7.51it/s]               \n",
            "freeglut-2.8.1       |         | : 100% 1.0/1 [00:00<00:00,  6.71it/s]               \n",
            "freetype-2.8         |         | : 100% 1.0/1 [00:00<00:00,  4.55it/s]               \n",
            "future-0.16.0        |         | : 100% 1.0/1 [00:00<00:00,  3.02it/s]              \n",
            "gflags-2.2.1         |         | : 100% 1.0/1 [00:00<00:00,  9.18it/s]\n",
            "glib-2.56.1          |         | : 100% 1.0/1 [00:01<00:00,  1.69s/it]               \n",
            "glog-0.3.5           |         | : 100% 1.0/1 [00:00<00:00,  8.60it/s]\n",
            "graphite2-1.3.11     |         | : 100% 1.0/1 [00:00<00:00, 12.27it/s]\n",
            "gst-plugins-base-1.1 |         | : 100% 1.0/1 [00:01<00:00,  1.24s/it]               \n",
            "gstreamer-1.14.0     |         | : 100% 1.0/1 [00:00<00:00,  1.23it/s]               \n",
            "h5py-2.8.0           |         | : 100% 1.0/1 [00:00<00:00,  3.28it/s]              \n",
            "harfbuzz-1.7.6       |         | : 100% 1.0/1 [00:00<00:00,  3.88it/s]               \n",
            "hdf5-1.8.18          |         | : 100% 1.0/1 [00:00<00:00,  1.07it/s]               \n",
            "icu-58.2             |         | : 100% 1.0/1 [00:04<00:00,  4.20s/it]               \n",
            "intel-openmp-2018.0. |         | : 100% 1.0/1 [00:00<00:00,  6.26it/s]               \n",
            "jasper-2.0.14        |         | : 100% 1.0/1 [00:00<00:00,  3.62it/s]               \n",
            "jpeg-9b              |         | : 100% 1.0/1 [00:00<00:00,  8.98it/s]\n",
            "kiwisolver-1.0.1     |         | : 100% 1.0/1 [00:00<00:00, 14.17it/s]\n",
            "libedit-3.1          |         | : 100% 1.0/1 [00:00<00:00, 10.26it/s]\n",
            "libffi-3.2.1         |         | : 100% 1.0/1 [00:00<00:00, 15.40it/s]\n",
            "libgcc-ng-7.2.0      |         | : 100% 1.0/1 [00:01<00:00,  1.13s/it]               \n",
            "libgfortran-ng-7.2.0 |         | : 100% 1.0/1 [00:00<00:00,  3.24it/s]               \n",
            "libglu-9.0.0         |         | : 100% 1.0/1 [00:00<00:00,  5.31it/s]               \n",
            "libopus-1.2.1        |         | : 100% 1.0/1 [00:00<00:00,  7.90it/s]               \n",
            "libpng-1.6.34        |         | : 100% 1.0/1 [00:00<00:00,  7.56it/s]               \n",
            "libprotobuf-3.5.2    |         | : 100% 1.0/1 [00:01<00:00,  1.14s/it]               \n",
            "libstdcxx-ng-7.2.0   |         | : 100% 1.0/1 [00:00<00:00,  1.94it/s]               \n",
            "libtiff-4.0.9        |         | : 100% 1.0/1 [00:00<00:00,  5.56it/s]               \n",
            "libvpx-1.6.1         |         | : 100% 1.0/1 [00:00<00:00,  2.03it/s]               \n",
            "libxcb-1.13          |         | : 100% 1.0/1 [00:00<00:00,  3.95it/s]               \n",
            "libxml2-2.9.8        |         | : 100% 1.0/1 [00:00<00:00,  1.59it/s]               \n",
            "matplotlib-2.2.2     |         | : 100% 1.0/1 [00:01<00:00,  1.44s/it]              \n",
            "mkl-2018.0.2         |         | : 100% 1.0/1 [00:42<00:00, 42.37s/it]                \n",
            "mkl_fft-1.0.1        |         | : 100% 1.0/1 [00:00<00:00, 10.74it/s]\n",
            "mkl_random-1.0.1     |         | : 100% 1.0/1 [00:00<00:00,  7.82it/s]              \n",
            "ncurses-6.0          |         | : 100% 1.0/1 [00:01<00:00,  1.00s/it]              \n",
            "ninja-1.8.2          |         | : 100% 1.0/1 [00:00<00:00,  3.36it/s]               \n",
            "numpy-1.14.3         |         | : 100% 1.0/1 [00:00<00:00, 13.11it/s]\n",
            "numpy-base-1.14.3    |         | : 100% 1.0/1 [00:01<00:00,  1.15s/it]               \n",
            "olefile-0.45.1       |         | : 100% 1.0/1 [00:00<00:00, 13.22it/s]\n",
            "opencv-3.3.1         |         | : 100% 1.0/1 [00:07<00:00,  7.62s/it]               \n",
            "openssl-1.0.2o       |         | : 100% 1.0/1 [00:01<00:00,  1.29s/it]              \n",
            "pcre-8.42            |         | : 100% 1.0/1 [00:00<00:00,  8.47it/s]\n",
            "pillow-5.1.0         |         | : 100% 1.0/1 [00:00<00:00,  3.99it/s]               \n",
            "pip-10.0.1           |         | : 100% 1.0/1 [00:00<00:00,  1.48it/s]              \n",
            "pixman-0.34.0        |         | : 100% 1.0/1 [00:00<00:00,  5.81it/s]               \n",
            "protobuf-3.5.2       |         | : 100% 1.0/1 [00:00<00:00,  2.28it/s]               \n",
            "pycparser-2.18       |         | : 100% 1.0/1 [00:00<00:00,  9.00it/s]\n",
            "pyparsing-2.2.0      |         | : 100% 1.0/1 [00:00<00:00, 12.29it/s]\n",
            "pyqt-5.9.2           |         | : 100% 1.0/1 [00:01<00:00,  1.85s/it]               \n",
            "python-3.6.5         |         | : 100% 1.0/1 [00:05<00:00,  5.13s/it]               \n",
            "python-dateutil-2.7. |         | : 100% 1.0/1 [00:00<00:00,  9.09it/s]\n",
            "pytorch-0.4.1        |         | : 100% 1.0/1 [01:15<00:00, 75.02s/it]               \n",
            "pytz-2018.4          |         | : 100% 1.0/1 [00:00<00:00,  3.28it/s]               \n",
            "pyyaml-3.12          |         | : 100% 1.0/1 [00:00<00:00,  9.78it/s]\n",
            "qt-5.9.5             |         | : 100% 1.0/1 [00:18<00:00, 18.91s/it]              \n",
            "readline-7.0         |         | : 100% 1.0/1 [00:00<00:00,  3.67it/s]               \n",
            "scikit-learn-0.19.1  |         | : 100% 1.0/1 [00:01<00:00,  1.43s/it]               \n",
            "scipy-1.1.0          |         | : 100% 1.0/1 [00:03<00:00,  3.85s/it]               \n",
            "setuptools-39.1.0    |         | : 100% 1.0/1 [00:00<00:00,  3.98it/s]               \n",
            "sip-4.19.8           |         | : 100% 1.0/1 [00:00<00:00,  9.56it/s]\n",
            "six-1.11.0           |         | : 100% 1.0/1 [00:00<00:00, 16.81it/s]\n",
            "sqlite-3.23.1        |         | : 100% 1.0/1 [00:00<00:00,  2.97it/s]               \n",
            "tk-8.6.7             |         | : 100% 1.0/1 [00:00<00:00,  1.30it/s]               \n",
            "torchvision-0.2.1    |         | : 100% 1.0/1 [00:00<00:00,  3.02it/s]                \n",
            "tornado-5.0.2        |         | : 100% 1.0/1 [00:00<00:00,  2.77it/s]               \n",
            "tqdm-4.23.0          |         | : 100% 1.0/1 [00:00<00:00, 14.17it/s]\n",
            "wheel-0.31.0         |         | : 100% 1.0/1 [00:00<00:00, 12.75it/s]\n",
            "xz-5.2.3             |         | : 100% 1.0/1 [00:00<00:00,  5.79it/s]               \n",
            "yaml-0.1.7           |         | : 100% 1.0/1 [00:00<00:00, 13.59it/s]\n",
            "zlib-1.2.11          |         | : 100% 1.0/1 [00:00<00:00, 13.36it/s]\n",
            "progress-1.4         |         | : 100% 1.0/1 [00:00<00:00, 14.89it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Up0uvWME32N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3fd4245-544a-46b0-e65a-ad58bac2607f"
      },
      "source": [
        "!pip install -r \"/content/drive/My Drive/pd/req.txt\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4 MB 70 kB/s \n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.21-cp36-cp36m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 60.6 MB/s \n",
            "\u001b[?25hCollecting numba\n",
            "  Downloading numba-0.51.2-cp36-cp36m-manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting progress\n",
            "  Downloading progress-1.5.tar.gz (5.8 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.3.2-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 55.2 MB/s \n",
            "\u001b[?25hCollecting easydict\n",
            "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 87.3 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.13.3\n",
            "  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from numba->-r /content/drive/My Drive/pd/req.txt (line 3)) (49.6.0.post20200814)\n",
            "Collecting llvmlite<0.35,>=0.34.0.dev0\n",
            "  Downloading llvmlite-0.34.0-cp36-cp36m-manylinux2010_x86_64.whl (24.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/site-packages (from matplotlib->-r /content/drive/My Drive/pd/req.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r /content/drive/My Drive/pd/req.txt (line 5)) (1.11.0)\n",
            "Building wheels for collected packages: progress, easydict\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-py3-none-any.whl size=8074 sha256=1135c99c7a7d61004bb156ee66946acc4f039a6fa6846b1d9625a8ee8c397524\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/d6/71/e87d26b0205f2c12e55a1a554214668ee324a962bad857c56a\n",
            "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6350 sha256=07ead6697916674f315dbf752bc46d40e4a64acc0a3dcbd2460f9b95f4bb6240\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/79/e4/4e55effe206295359b37e0f9db3e68a1197ba396682807dadb\n",
            "Successfully built progress easydict\n",
            "Installing collected packages: numpy, opencv-python, Cython, llvmlite, numba, progress, kiwisolver, pyparsing, cycler, python-dateutil, pillow, matplotlib, easydict, scipy\n",
            "Successfully installed Cython-0.29.21 cycler-0.10.0 easydict-1.9 kiwisolver-1.2.0 llvmlite-0.34.0 matplotlib-3.3.2 numba-0.51.2 numpy-1.19.2 opencv-python-4.4.0.42 pillow-7.2.0 progress-1.5 pyparsing-2.4.7 python-dateutil-2.8.1 scipy-1.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND27BwBlGcGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/ExtremeNet/external/nms.pyx\" \"/content/drive/My Drive/pd/external\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQ9IlZeGTFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "5f075d31-8e5c-43eb-b4e2-70be1b000c9f"
      },
      "source": [
        "!cd \"/content/drive/My Drive/pd/external\" && python \"/content/drive/My Drive/pd/external/setup.py\" build_ext --inplace\n",
        "!rm -rf build"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling nms.pyx because it changed.\n",
            "[1/1] Cythonizing nms.pyx\n",
            "/usr/local/lib/python3.6/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/My Drive/pd/external/nms.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running build_ext\n",
            "building 'nms' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/numpy/core/include -I/usr/local/include/python3.6m -c nms.c -o build/temp.linux-x86_64-3.6/nms.o -Wno-cpp -Wno-unused-function\n",
            "\u001b[01m\u001b[Knms.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_3nms_2soft_nms\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Knms.c:3444:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Knms.c:3955:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Knms.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_3nms_4soft_nms_with_points\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Knms.c:5355:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Knms.c:6522:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Knms.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_3nms_6soft_nms_merge\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Knms.c:8089:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Knms.c:8792:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_8 = ((__pyx_v_pos \u001b[01;35m\u001b[K<\u001b[m\u001b[K __pyx_v_N) != 0);\n",
            "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/nms.o -o /content/drive/My Drive/pd/external/nms.cpython-36m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-KfxgbWHd75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "bf494a03-4178-49a6-a656-a30fcaed0d1d"
      },
      "source": [
        "!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.4\n",
            "  Downloading torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 21 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5\n",
            "  Downloading torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/site-packages (from torchvision==0.5) (7.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from torchvision==0.5) (1.19.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from torchvision==0.5) (1.11.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aKQFljBHp3s",
        "colab_type": "text"
      },
      "source": [
        "## Configuration files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvAmnhocHjkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "232ab058-f5c1-4f58-dd47-4ef56cb3e9b8"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pprint\n",
        "import argparse\n",
        "import importlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self._configs = {}\n",
        "        self._configs[\"dataset\"] = None\n",
        "        self._configs[\"sampling_function\"] = \"kp_detection\"\n",
        "\n",
        "        # Training Config\n",
        "        self._configs[\"display\"]           = 5\n",
        "        self._configs[\"snapshot\"]          = 5000\n",
        "        self._configs[\"stepsize\"]          = 450000\n",
        "        self._configs[\"learning_rate\"]     = 0.00025\n",
        "        self._configs[\"decay_rate\"]        = 10\n",
        "        self._configs[\"max_iter\"]          = 500000\n",
        "        self._configs[\"val_iter\"]          = 100\n",
        "        self._configs[\"batch_size\"]        = 1\n",
        "        self._configs[\"snapshot_name\"]     = None\n",
        "        self._configs[\"prefetch_size\"]     = 100\n",
        "        self._configs[\"weight_decay\"]      = False\n",
        "        self._configs[\"weight_decay_rate\"] = 1e-5\n",
        "        self._configs[\"weight_decay_type\"] = \"l2\"\n",
        "        self._configs[\"pretrain\"]          = None\n",
        "        self._configs[\"opt_algo\"]          = \"adam\"\n",
        "        self._configs[\"chunk_sizes\"]       = None\n",
        "\n",
        "        # Directories\n",
        "        self._configs[\"data_dir\"]   = \"./data\"\n",
        "        self._configs[\"cache_dir\"]  = \"./cache\"\n",
        "        self._configs[\"config_dir\"] = \"./config\"\n",
        "        self._configs[\"result_dir\"] = \"./results\"\n",
        "\n",
        "        # Split\n",
        "        self._configs[\"train_split\"] = \"trainval\"\n",
        "        self._configs[\"val_split\"]   = \"minival\"\n",
        "        self._configs[\"test_split\"]  = \"testdev\"\n",
        "\n",
        "        # Rng\n",
        "        self._configs[\"data_rng\"] = np.random.RandomState(123)\n",
        "        self._configs[\"nnet_rng\"] = np.random.RandomState(317)\n",
        "\n",
        "    @property\n",
        "    def chunk_sizes(self):\n",
        "        return self._configs[\"chunk_sizes\"]\n",
        "\n",
        "    @property\n",
        "    def train_split(self):\n",
        "        return self._configs[\"train_split\"]\n",
        "\n",
        "    @property\n",
        "    def val_split(self):\n",
        "        return self._configs[\"val_split\"]\n",
        "\n",
        "    @property\n",
        "    def test_split(self):\n",
        "        return self._configs[\"test_split\"]\n",
        "\n",
        "    @property\n",
        "    def full(self):\n",
        "        return self._configs\n",
        "\n",
        "    @property\n",
        "    def sampling_function(self):\n",
        "        return self._configs[\"sampling_function\"]\n",
        "\n",
        "    @property\n",
        "    def data_rng(self):\n",
        "        return self._configs[\"data_rng\"]\n",
        "\n",
        "    @property\n",
        "    def nnet_rng(self):\n",
        "        return self._configs[\"nnet_rng\"]\n",
        "\n",
        "    @property\n",
        "    def opt_algo(self):\n",
        "        return self._configs[\"opt_algo\"]\n",
        "\n",
        "    @property\n",
        "    def weight_decay_type(self):\n",
        "        return self._configs[\"weight_decay_type\"]\n",
        "\n",
        "    @property\n",
        "    def prefetch_size(self):\n",
        "        return self._configs[\"prefetch_size\"]\n",
        "\n",
        "    @property\n",
        "    def pretrain(self):\n",
        "        return self._configs[\"pretrain\"]\n",
        "\n",
        "    @property\n",
        "    def weight_decay_rate(self):\n",
        "        return self._configs[\"weight_decay_rate\"]\n",
        "\n",
        "    @property\n",
        "    def weight_decay(self):\n",
        "        return self._configs[\"weight_decay\"]\n",
        "\n",
        "    @property\n",
        "    def result_dir(self):\n",
        "        result_dir = os.path.join(self._configs[\"result_dir\"], self.snapshot_name)\n",
        "        if not os.path.exists(result_dir):\n",
        "            os.makedirs(result_dir)\n",
        "        return result_dir\n",
        "\n",
        "    @property\n",
        "    def dataset(self):\n",
        "        return self._configs[\"dataset\"]\n",
        "\n",
        "    @property\n",
        "    def snapshot_name(self):\n",
        "        return self._configs[\"snapshot_name\"]\n",
        "\n",
        "    @property\n",
        "    def snapshot_dir(self):\n",
        "        snapshot_dir = os.path.join(self.cache_dir, \"nnet\", self.snapshot_name)\n",
        "\n",
        "        if not os.path.exists(snapshot_dir):\n",
        "            os.makedirs(snapshot_dir)\n",
        "\n",
        "        return snapshot_dir\n",
        "\n",
        "    @property\n",
        "    def snapshot_file(self):\n",
        "        snapshot_file = os.path.join(self.snapshot_dir, self.snapshot_name + \"_{}.pkl\")\n",
        "        return snapshot_file\n",
        "\n",
        "    @property\n",
        "    def config_dir(self):\n",
        "        return self._configs[\"config_dir\"]\n",
        "\n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self._configs[\"batch_size\"]\n",
        "\n",
        "    @property\n",
        "    def max_iter(self):\n",
        "        return self._configs[\"max_iter\"]\n",
        "\n",
        "    @property\n",
        "    def learning_rate(self):\n",
        "        return self._configs[\"learning_rate\"]\n",
        "\n",
        "    @property\n",
        "    def decay_rate(self):\n",
        "        return self._configs[\"decay_rate\"]\n",
        "\n",
        "    @property\n",
        "    def stepsize(self):\n",
        "        return self._configs[\"stepsize\"]\n",
        "\n",
        "    @property\n",
        "    def snapshot(self):\n",
        "        return self._configs[\"snapshot\"]\n",
        "\n",
        "    @property\n",
        "    def display(self):\n",
        "        return self._configs[\"display\"]\n",
        "\n",
        "    @property\n",
        "    def val_iter(self):\n",
        "        return self._configs[\"val_iter\"]\n",
        "\n",
        "    @property\n",
        "    def data_dir(self):\n",
        "        return self._configs[\"data_dir\"]\n",
        "\n",
        "    @property\n",
        "    def cache_dir(self):\n",
        "        if not os.path.exists(self._configs[\"cache_dir\"]):\n",
        "            os.makedirs(self._configs[\"cache_dir\"])\n",
        "        return self._configs[\"cache_dir\"]\n",
        "\n",
        "    def update_config(self, new):\n",
        "        for key in new:\n",
        "            if key in self._configs:\n",
        "                self._configs[key] = new[key]\n",
        "\n",
        "system_configs = Config()\n",
        "print(system_configs)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.Config object at 0x7fd38d0de4e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiN9HCmKIDsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import importlib\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules import Module\n",
        "from torch.nn.parallel.scatter_gather import gather\n",
        "from torch.nn.parallel.replicate import replicate\n",
        "from torch.nn.parallel.parallel_apply import parallel_apply\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parallel._functions import Scatter, Gather\n",
        "\n",
        "\n",
        "def scatter(inputs, target_gpus, dim=0, chunk_sizes=None):\n",
        "    r\"\"\"\n",
        "    Slices variables into approximately equal chunks and\n",
        "    distributes them across given GPUs. Duplicates\n",
        "    references to objects that are not variables. Does not\n",
        "    support Tensors.\n",
        "    \"\"\"\n",
        "    def scatter_map(obj):\n",
        "        if isinstance(obj, Variable):\n",
        "            return Scatter.apply(target_gpus, chunk_sizes, dim, obj)\n",
        "        assert not torch.is_tensor(obj), \"Tensors not supported in scatter.\"\n",
        "        if isinstance(obj, tuple):\n",
        "            return list(zip(*map(scatter_map, obj)))\n",
        "        if isinstance(obj, list):\n",
        "            return list(map(list, zip(*map(scatter_map, obj))))\n",
        "        if isinstance(obj, dict):\n",
        "            return list(map(type(obj), zip(*map(scatter_map, obj.items()))))\n",
        "        return [obj for targets in target_gpus]\n",
        "\n",
        "    return scatter_map(inputs)\n",
        "\n",
        "\n",
        "def scatter_kwargs(inputs, kwargs, target_gpus, dim=0, chunk_sizes=None):\n",
        "    r\"\"\"Scatter with support for kwargs dictionary\"\"\"\n",
        "    inputs = scatter(inputs, target_gpus, dim, chunk_sizes) if inputs else []\n",
        "    kwargs = scatter(kwargs, target_gpus, dim, chunk_sizes) if kwargs else []\n",
        "    if len(inputs) < len(kwargs):\n",
        "        inputs.extend([() for _ in range(len(kwargs) - len(inputs))])\n",
        "    elif len(kwargs) < len(inputs):\n",
        "        kwargs.extend([{} for _ in range(len(inputs) - len(kwargs))])\n",
        "    inputs = tuple(inputs)\n",
        "    kwargs = tuple(kwargs)\n",
        "    return inputs, kwargs\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6yk-0zdISiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataParallel(Module):\n",
        "    r\"\"\"Implements data parallelism at the module level.\n",
        "\n",
        "    This container parallelizes the application of the given module by\n",
        "    splitting the input across the specified devices by chunking in the batch\n",
        "    dimension. In the forward pass, the module is replicated on each device,\n",
        "    and each replica handles a portion of the input. During the backwards\n",
        "    pass, gradients from each replica are summed into the original module.\n",
        "\n",
        "    The batch size should be larger than the number of GPUs used. It should\n",
        "    also be an integer multiple of the number of GPUs so that each chunk is the\n",
        "    same size (so that each GPU processes the same number of samples).\n",
        "\n",
        "    See also: :ref:`cuda-nn-dataparallel-instead`\n",
        "\n",
        "    Arbitrary positional and keyword inputs are allowed to be passed into\n",
        "    DataParallel EXCEPT Tensors. All variables will be scattered on dim\n",
        "    specified (default 0). Primitive types will be broadcasted, but all\n",
        "    other types will be a shallow copy and can be corrupted if written to in\n",
        "    the model's forward pass.\n",
        "\n",
        "    Args:\n",
        "        module: module to be parallelized\n",
        "        device_ids: CUDA devices (default: all devices)\n",
        "        output_device: device location of output (default: device_ids[0])\n",
        "\n",
        "    Example::\n",
        "\n",
        "        >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n",
        "        >>> output = net(input_var)\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well\n",
        "\n",
        "    def __init__(self, module, device_ids=None, output_device=None, dim=0, chunk_sizes=None):\n",
        "        super(DataParallel, self).__init__()\n",
        "\n",
        "        if not torch.cuda.is_available():\n",
        "            self.module = module\n",
        "            self.device_ids = []\n",
        "            return\n",
        "\n",
        "        if device_ids is None:\n",
        "            device_ids = list(range(torch.cuda.device_count()))\n",
        "        if output_device is None:\n",
        "            output_device = device_ids[0]\n",
        "        self.dim = dim\n",
        "        self.module = module\n",
        "        self.device_ids = device_ids\n",
        "        self.chunk_sizes = chunk_sizes\n",
        "        self.output_device = output_device\n",
        "        if len(self.device_ids) == 1:\n",
        "            self.module.cuda(device_ids[0])\n",
        "\n",
        "    def forward(self, *inputs, **kwargs):\n",
        "        if not self.device_ids:\n",
        "            return self.module(*inputs, **kwargs)\n",
        "        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids, self.chunk_sizes)\n",
        "        if len(self.device_ids) == 1:\n",
        "            return self.module(*inputs[0], **kwargs[0])\n",
        "        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n",
        "        outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
        "        return self.gather(outputs, self.output_device)\n",
        "\n",
        "    def replicate(self, module, device_ids):\n",
        "        return replicate(module, device_ids)\n",
        "\n",
        "    def scatter(self, inputs, kwargs, device_ids, chunk_sizes):\n",
        "        return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim, chunk_sizes=self.chunk_sizes)\n",
        "\n",
        "    def parallel_apply(self, replicas, inputs, kwargs):\n",
        "        return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
        "\n",
        "    def gather(self, outputs, output_device):\n",
        "        return gather(outputs, output_device, dim=self.dim)\n",
        "\n",
        "\n",
        "def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):\n",
        "    r\"\"\"Evaluates module(input) in parallel across the GPUs given in device_ids.\n",
        "\n",
        "    This is the functional version of the DataParallel module.\n",
        "\n",
        "    Args:\n",
        "        module: the module to evaluate in parallel\n",
        "        inputs: inputs to the module\n",
        "        device_ids: GPU ids on which to replicate module\n",
        "        output_device: GPU location of the output  Use -1 to indicate the CPU.\n",
        "            (default: device_ids[0])\n",
        "    Returns:\n",
        "        a Variable containing the result of module(input) located on\n",
        "        output_device\n",
        "    \"\"\"\n",
        "    if not isinstance(inputs, tuple):\n",
        "        inputs = (inputs,)\n",
        "\n",
        "    if device_ids is None:\n",
        "        device_ids = list(range(torch.cuda.device_count()))\n",
        "\n",
        "    if output_device is None:\n",
        "        output_device = device_ids[0]\n",
        "\n",
        "    inputs, module_kwargs = scatter_kwargs(inputs, module_kwargs, device_ids, dim)\n",
        "    if len(device_ids) == 1:\n",
        "        return module(*inputs[0], **module_kwargs[0])\n",
        "    used_device_ids = device_ids[:len(inputs)]\n",
        "    replicas = replicate(module, used_device_ids)\n",
        "    outputs = parallel_apply(replicas, inputs, module_kwargs, used_device_ids)\n",
        "    return gather(outputs, output_device, dim)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5XqSeYIYpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "torch.manual_seed(317)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, model, loss):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.loss  = loss\n",
        "\n",
        "    def forward(self, xs, ys, **kwargs):\n",
        "        preds = self.model(*xs, **kwargs)\n",
        "        loss  = self.loss(preds, ys, **kwargs)\n",
        "        return loss\n",
        "\n",
        "# for model backward compatibility\n",
        "# previously model was wrapped by DataParallel module\n",
        "class DummyModule(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(DummyModule, self).__init__()\n",
        "        self.module = model\n",
        "\n",
        "    def forward(self, *xs, **kwargs):\n",
        "        return self.module(*xs, **kwargs)\n",
        "\n",
        "class NetworkFactory(object):\n",
        "    def __init__(self, db):\n",
        "        super(NetworkFactory, self).__init__()\n",
        "\n",
        "        module_file = \"models.{}\".format(system_configs.snapshot_name)\n",
        "        print(\"module_file: {}\".format(module_file))\n",
        "        nnet_module = importlib.import_module(module_file)\n",
        "\n",
        "        self.model   = DummyModule(nnet_module.model(db))\n",
        "        self.loss    = nnet_module.loss\n",
        "        self.network = Network(self.model, self.loss)\n",
        "        self.network = DataParallel(self.network, chunk_sizes=system_configs.chunk_sizes)\n",
        "\n",
        "        total_params = 0\n",
        "        for params in self.model.parameters():\n",
        "            num_params = 1\n",
        "            for x in params.size():\n",
        "                num_params *= x\n",
        "            total_params += num_params\n",
        "        print(\"total parameters: {}\".format(total_params))\n",
        "\n",
        "        if system_configs.opt_algo == \"adam\":\n",
        "            self.optimizer = torch.optim.Adam(\n",
        "                filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "            )\n",
        "        elif system_configs.opt_algo == \"sgd\":\n",
        "            self.optimizer = torch.optim.SGD(\n",
        "                filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "                lr=system_configs.learning_rate, \n",
        "                momentum=0.9, weight_decay=0.0001\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"unknown optimizer\")\n",
        "\n",
        "    def cuda(self):\n",
        "        self.model.cuda()\n",
        "\n",
        "    def train_mode(self):\n",
        "        self.network.train()\n",
        "\n",
        "    def eval_mode(self):\n",
        "        self.network.eval()\n",
        "\n",
        "    def train(self, xs, ys, **kwargs):\n",
        "        xs = [x.cuda(non_blocking=True) for x in xs]\n",
        "        ys = [y.cuda(non_blocking=True) for y in ys]\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.network(xs, ys)\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss\n",
        "\n",
        "    def validate(self, xs, ys, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            xs = [x.cuda(non_blocking=True) for x in xs]\n",
        "            ys = [y.cuda(non_blocking=True) for y in ys]\n",
        "\n",
        "            loss = self.network(xs, ys)\n",
        "            loss = loss.mean()\n",
        "            return loss\n",
        "\n",
        "    def test(self, xs, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            xs = [x.cuda(non_blocking=True) for x in xs]\n",
        "            return self.model(*xs, **kwargs)\n",
        "\n",
        "    def set_lr(self, lr):\n",
        "        print(\"setting learning rate to: {}\".format(lr))\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr\n",
        "\n",
        "    def load_pretrained_params(self, pretrained_model):\n",
        "        print(\"loading from {}\".format(pretrained_model))\n",
        "        with open(pretrained_model, \"rb\") as f:\n",
        "            params = torch.load(f)\n",
        "            self.model.load_state_dict(params, strict=False)\n",
        "\n",
        "    def load_params(self, iteration):\n",
        "        cache_file = system_configs.snapshot_file.format(iteration)\n",
        "        print(\"loading model from {}\".format(cache_file))\n",
        "        with open(cache_file, \"rb\") as f:\n",
        "            params = torch.load(f)\n",
        "            self.model.load_state_dict(params)\n",
        "\n",
        "    def save_params(self, iteration):\n",
        "        cache_file = system_configs.snapshot_file.format(iteration)\n",
        "        print(\"saving model to {}\".format(cache_file))\n",
        "        with open(cache_file, \"wb\") as f:\n",
        "            params = self.model.state_dict()\n",
        "            torch.save(params, f)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMNZNj9PIa-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_(image, mean, std):\n",
        "    image -= mean\n",
        "    image /= std\n",
        "\n",
        "    \n",
        "def crop_image(image, center, size):\n",
        "    cty, ctx            = center\n",
        "    height, width       = size\n",
        "    im_height, im_width = image.shape[0:2]\n",
        "    cropped_image       = np.zeros((height, width, 3), dtype=image.dtype)\n",
        "\n",
        "    x0, x1 = max(0, ctx - width // 2), min(ctx + width // 2, im_width)\n",
        "    y0, y1 = max(0, cty - height // 2), min(cty + height // 2, im_height)\n",
        "\n",
        "    left, right = ctx - x0, x1 - ctx\n",
        "    top, bottom = cty - y0, y1 - cty\n",
        "\n",
        "    cropped_cty, cropped_ctx = height // 2, width // 2\n",
        "    y_slice = slice(cropped_cty - top, cropped_cty + bottom)\n",
        "    x_slice = slice(cropped_ctx - left, cropped_ctx + right)\n",
        "    cropped_image[y_slice, x_slice, :] = image[y0:y1, x0:x1, :]\n",
        "\n",
        "    border = np.array([\n",
        "       cropped_cty - top,\n",
        "       cropped_cty + bottom,\n",
        "       cropped_ctx - left,\n",
        "       cropped_ctx + right\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    offset = np.array([\n",
        "        cty - height // 2,\n",
        "        ctx - width  // 2\n",
        "    ])\n",
        "\n",
        "    return cropped_image, border, offset\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwI-S_1TI3bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd \"/content/drive/My Drive/pd\" && python nmsaccess.py"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlBqDurmJ50x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def colormap(rgb=False):\n",
        "    color_list = np.array(\n",
        "        [\n",
        "            0.000, 0.447, 0.741,\n",
        "            0.850, 0.325, 0.098,\n",
        "            0.929, 0.694, 0.125,\n",
        "            0.494, 0.184, 0.556,\n",
        "            0.466, 0.674, 0.188,\n",
        "            0.301, 0.745, 0.933,\n",
        "            0.635, 0.078, 0.184,\n",
        "            0.300, 0.300, 0.300,\n",
        "            0.600, 0.600, 0.600,\n",
        "            1.000, 0.000, 0.000,\n",
        "            1.000, 0.500, 0.000,\n",
        "            0.749, 0.749, 0.000,\n",
        "            0.000, 1.000, 0.000,\n",
        "            0.000, 0.000, 1.000,\n",
        "            0.667, 0.000, 1.000,\n",
        "            0.333, 0.333, 0.000,\n",
        "            0.333, 0.667, 0.000,\n",
        "            0.333, 1.000, 0.000,\n",
        "            0.667, 0.333, 0.000,\n",
        "            0.667, 0.667, 0.000,\n",
        "            0.667, 1.000, 0.000,\n",
        "            1.000, 0.333, 0.000,\n",
        "            1.000, 0.667, 0.000,\n",
        "            1.000, 1.000, 0.000,\n",
        "            0.000, 0.333, 0.500,\n",
        "            0.000, 0.667, 0.500,\n",
        "            0.000, 1.000, 0.500,\n",
        "            0.333, 0.000, 0.500,\n",
        "            0.333, 0.333, 0.500,\n",
        "            0.333, 0.667, 0.500,\n",
        "            0.333, 1.000, 0.500,\n",
        "            0.667, 0.000, 0.500,\n",
        "            0.667, 0.333, 0.500,\n",
        "            0.667, 0.667, 0.500,\n",
        "            0.667, 1.000, 0.500,\n",
        "            1.000, 0.000, 0.500,\n",
        "            1.000, 0.333, 0.500,\n",
        "            1.000, 0.667, 0.500,\n",
        "            1.000, 1.000, 0.500,\n",
        "            0.000, 0.333, 1.000,\n",
        "            0.000, 0.667, 1.000,\n",
        "            0.000, 1.000, 1.000,\n",
        "            0.333, 0.000, 1.000,\n",
        "            0.333, 0.333, 1.000,\n",
        "            0.333, 0.667, 1.000,\n",
        "            0.333, 1.000, 1.000,\n",
        "            0.667, 0.000, 1.000,\n",
        "            0.667, 0.333, 1.000,\n",
        "            0.667, 0.667, 1.000,\n",
        "            0.667, 1.000, 1.000,\n",
        "            1.000, 0.000, 1.000,\n",
        "            1.000, 0.333, 1.000,\n",
        "            1.000, 0.667, 1.000,\n",
        "            0.167, 0.000, 0.000,\n",
        "            0.333, 0.000, 0.000,\n",
        "            0.500, 0.000, 0.000,\n",
        "            0.667, 0.000, 0.000,\n",
        "            0.833, 0.000, 0.000,\n",
        "            1.000, 0.000, 0.000,\n",
        "            0.000, 0.167, 0.000,\n",
        "            0.000, 0.333, 0.000,\n",
        "            0.000, 0.500, 0.000,\n",
        "            0.000, 0.667, 0.000,\n",
        "            0.000, 0.833, 0.000,\n",
        "            0.000, 1.000, 0.000,\n",
        "            0.000, 0.000, 0.167,\n",
        "            0.000, 0.000, 0.333,\n",
        "            0.000, 0.000, 0.500,\n",
        "            0.000, 0.000, 0.667,\n",
        "            0.000, 0.000, 0.833,\n",
        "            0.000, 0.000, 1.000,\n",
        "            0.000, 0.000, 0.000,\n",
        "            0.143, 0.143, 0.143,\n",
        "            0.286, 0.286, 0.286,\n",
        "            0.429, 0.429, 0.429,\n",
        "            0.571, 0.571, 0.571,\n",
        "            0.714, 0.714, 0.714,\n",
        "            0.857, 0.857, 0.857,\n",
        "            1.000, 1.000, 1.000\n",
        "        ]\n",
        "    ).astype(np.float32)\n",
        "    color_list = color_list.reshape((-1, 3)) * 255\n",
        "    if not rgb:\n",
        "        color_list = color_list[:, ::-1]\n",
        "    return color_list\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTQbdSsTKLjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "_GRAY = (218, 227, 218)\n",
        "_GREEN = (18, 127, 15)\n",
        "_WHITE = (255, 255, 255)\n",
        "\n",
        "def vis_mask(img, mask, col, alpha=0.4, show_border=True, border_thick=2):\n",
        "    \"\"\"Visualizes a single binary mask.\"\"\"\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    idx = np.nonzero(mask)\n",
        "\n",
        "    img[idx[0], idx[1], :] *= 1.0 - alpha\n",
        "    img[idx[0], idx[1], :] += alpha * col\n",
        "\n",
        "    if show_border:\n",
        "        # How to use `cv2.findContours` in different OpenCV versions?\n",
        "        # https://stackoverflow.com/questions/48291581/how-to-use-cv2-findcontours-in-different-opencv-versions/48292371#48292371\n",
        "        contours = cv2.findContours(\n",
        "            mask.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]\n",
        "        cv2.drawContours(img, contours, -1, _WHITE, border_thick, cv2.LINE_AA)\n",
        "\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "\n",
        "def vis_octagon(img, extreme_points, col, border_thick=2):\n",
        "    \"\"\"Visualizes a single binary mask.\"\"\"\n",
        "\n",
        "    img = img.astype(np.uint8)\n",
        "    # COL = (col).astype(np.uint8).tolist()\n",
        "    # print('col', COL)\n",
        "    # octagon = get_octagon(extreme_points)\n",
        "    # octagon = np.array(octagon).reshape(8, 1, 2).astype(np.int32)\n",
        "    # cv2.polylines(img, [octagon], \n",
        "    #               True, COL, border_thick)\n",
        "    mask = extreme_point_to_octagon_mask(\n",
        "      extreme_points, img.shape[0], img.shape[1])\n",
        "\n",
        "    img = vis_mask(img, mask, col)\n",
        "\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "def vis_ex(img, extreme_points, col, border_thick=2):\n",
        "    \"\"\"Visualizes a single binary mask.\"\"\"\n",
        "\n",
        "    img = img.astype(np.uint8)\n",
        "    COL = (col).astype(np.uint8).tolist()\n",
        "    # print('col', COL)\n",
        "    ex = np.array(extreme_points).reshape(4, 2).astype(np.int32)\n",
        "    \n",
        "    L = 10\n",
        "    T = 0.7\n",
        "    cv2.arrowedLine(img, (ex[0][0], ex[0][1] + L), (ex[0][0], ex[0][1]), COL, border_thick, tipLength=T)\n",
        "    cv2.arrowedLine(img, (ex[1][0] + L, ex[1][1]), (ex[1][0], ex[1][1]), COL, border_thick, tipLength=T)\n",
        "    cv2.arrowedLine(img, (ex[2][0], ex[2][1] - L), (ex[2][0], ex[2][1]), COL, border_thick, tipLength=T)\n",
        "    cv2.arrowedLine(img, (ex[3][0] - L, ex[3][1]), (ex[3][0], ex[3][1]), COL, border_thick, tipLength=T)\n",
        "    \n",
        "    '''\n",
        "    R = 6\n",
        "    cv2.circle(img, (ex[0][0], ex[0][1]), R, COL, -1)\n",
        "    cv2.circle(img, (ex[1][0], ex[1][1]), R, COL, -1)\n",
        "    cv2.circle(img, (ex[2][0], ex[2][1]), R, COL, -1)\n",
        "    cv2.circle(img, (ex[3][0], ex[3][1]), R, COL, -1)\n",
        "\n",
        "    cv2.circle(img, (ex[0][0], ex[0][1]), R, _WHITE, 2)\n",
        "    cv2.circle(img, (ex[1][0], ex[1][1]), R, _WHITE, 2)\n",
        "    cv2.circle(img, (ex[2][0], ex[2][1]), R, _WHITE, 2)\n",
        "    cv2.circle(img, (ex[3][0], ex[3][1]), R, _WHITE, 2)\n",
        "    '''\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "\n",
        "def vis_class(img, pos, class_str, font_scale=0.35):\n",
        "    \"\"\"Visualizes the class.\"\"\"\n",
        "    img = img.astype(np.uint8)\n",
        "    x0, y0 = int(pos[0]), int(pos[1])\n",
        "    # Compute text size.\n",
        "    txt = class_str\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    ((txt_w, txt_h), _) = cv2.getTextSize(txt, font, font_scale, 1)\n",
        "    # Place text background.\n",
        "    if y0 - int(1.3 * txt_h) < 0:\n",
        "      y0 = y0 + int(1.6 * txt_h)\n",
        "    back_tl = x0, y0 - int(1.3 * txt_h)\n",
        "    back_br = x0 + txt_w, y0\n",
        "    cv2.rectangle(img, back_tl, back_br, _GREEN, -1)\n",
        "    # cv2.rectangle(img, back_tl, back_br, _GRAY, -1)\n",
        "    # Show text.\n",
        "    txt_tl = x0, y0 - int(0.3 * txt_h)\n",
        "    cv2.putText(img, txt, txt_tl, font, font_scale, _GRAY, lineType=cv2.LINE_AA)\n",
        "    # cv2.putText(img, txt, txt_tl, font, font_scale, (46, 52, 54), lineType=cv2.LINE_AA)\n",
        "    return img\n",
        "\n",
        "\n",
        "def vis_bbox(img, bbox, thick=2):\n",
        "    \"\"\"Visualizes a bounding box.\"\"\"\n",
        "    img = img.astype(np.uint8)\n",
        "    (x0, y0, w, h) = bbox\n",
        "    x1, y1 = int(x0 + w), int(y0 + h)\n",
        "    x0, y0 = int(x0), int(y0)\n",
        "    cv2.rectangle(img, (x0, y0), (x1, y1), _GREEN, thickness=thick)\n",
        "    return img\n",
        "\n",
        "def get_octagon(ex):\n",
        "  ex = np.array(ex).reshape(4, 2)\n",
        "  w, h = ex[3][0] - ex[1][0], ex[2][1] - ex[0][1]\n",
        "  t, l, b, r = ex[0][1], ex[1][0], ex[2][1], ex[3][0]\n",
        "  x = 8.\n",
        "  octagon = [[min(ex[0][0] + w / x, r), ex[0][1], \\\n",
        "              max(ex[0][0] - w / x, l), ex[0][1], \\\n",
        "              ex[1][0], max(ex[1][1] - h / x, t), \\\n",
        "              ex[1][0], min(ex[1][1] + h / x, b), \\\n",
        "              max(ex[2][0] - w / x, l), ex[2][1], \\\n",
        "              min(ex[2][0] + w / x, r), ex[2][1], \\\n",
        "              ex[3][0], min(ex[3][1] + h / x, b), \\\n",
        "              ex[3][0], max(ex[3][1] - h / x, t)\n",
        "              ]]\n",
        "  return octagon\n",
        "\n",
        "def extreme_point_to_octagon_mask(extreme_points, h, w):\n",
        "  octagon = get_octagon(extreme_points)\n",
        "  rles = mask_util.frPyObjects(octagon, h, w)\n",
        "  rle = mask_util.merge(rles)\n",
        "  mask = mask_util.decode(rle)\n",
        "  return mask\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ4HLms8KROX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/ExtremeNet/dextr.py\" \"/content/drive/My Drive/pd\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7hDX-46Uuiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "from torch.nn.functional import upsample\n",
        "this_dir = \"/content/drive/My Drive/ExtremeNet/dextr\"#os.path.dirname(__file__)\n",
        "sys.path.insert(0, 'dextr')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybuePVhWVck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "258b36c0-af4b-48a3-f708-60fc117034c8"
      },
      "source": [
        "!pip install mypath"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mypath\n",
            "  Downloading mypath-0.1.tar.gz (581 bytes)\n",
            "Building wheels for collected packages: mypath\n",
            "  Building wheel for mypath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mypath: filename=mypath-0.1-py3-none-any.whl size=961 sha256=67aa54c63a578c4ec3b0132be89b35f26c1990a02161cb5e0bb4890e6c641faf\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/04/70/4ab5a6a71bbabb739b3c5596b5a38d8eb09f8b0273cc13d335\n",
            "Successfully built mypath\n",
            "Installing collected packages: mypath\n",
            "Successfully installed mypath-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luHVUneLVcR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models.resnet as resnet\n",
        "import torch\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from torch.nn import functional as F\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDyWUanhWuR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Path(object):\n",
        "    @staticmethod\n",
        "    def db_root_dir(database):\n",
        "        if database == 'pascal':\n",
        "            return '/path/to/PASCAL/VOC2012'  # folder that contains VOCdevkit/.\n",
        "\n",
        "        elif database == 'sbd':\n",
        "            return '/path/to/SBD/'  # folder with img/, inst/, cls/, etc.\n",
        "        else:\n",
        "            print('Database {} not available.'.format(database))\n",
        "            raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def models_dir():\n",
        "        return 'models/'\n",
        "\n",
        "##\n",
        "\n",
        "affine_par = True\n",
        "\n",
        "\n",
        "def outS(i):\n",
        "    i = int(i)\n",
        "    i = (i+1)/2\n",
        "    i = int(np.ceil((i+1)/2.0))\n",
        "    i = (i+1)/2\n",
        "    return i\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1,  dilation_=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        padding = 1\n",
        "        if dilation_ == 2:\n",
        "            padding = 2\n",
        "        elif dilation_ == 4:\n",
        "            padding = 4\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n",
        "                               padding=padding, bias=False, dilation=dilation_)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ClassifierModule(nn.Module):\n",
        "\n",
        "    def __init__(self, dilation_series, padding_series, n_classes):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.conv2d_list = nn.ModuleList()\n",
        "        for dilation, padding in zip(dilation_series, padding_series):\n",
        "            self.conv2d_list.append(nn.Conv2d(2048, n_classes, kernel_size=3, stride=1, padding=padding, dilation=dilation, bias=True))\n",
        "\n",
        "        for m in self.conv2d_list:\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv2d_list[0](x)\n",
        "        for i in range(len(self.conv2d_list)-1):\n",
        "            out += self.conv2d_list[i+1](x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PSPModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Pyramid Scene Parsing module\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features=2048, out_features=512, sizes=(1, 2, 3, 6), n_classes=1):\n",
        "        super(PSPModule, self).__init__()\n",
        "        self.stages = []\n",
        "        self.stages = nn.ModuleList([self._make_stage_1(in_features, size) for size in sizes])\n",
        "        self.bottleneck = self._make_stage_2(in_features * (len(sizes)//4 + 1), out_features)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.final = nn.Conv2d(out_features, n_classes, kernel_size=1)\n",
        "\n",
        "    def _make_stage_1(self, in_features, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(in_features, in_features//4, kernel_size=1, bias=False)\n",
        "        bn = nn.BatchNorm2d(in_features//4, affine=affine_par)\n",
        "        relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        return nn.Sequential(prior, conv, bn, relu)\n",
        "\n",
        "    def _make_stage_2(self, in_features, out_features):\n",
        "        conv = nn.Conv2d(in_features, out_features, kernel_size=1, bias=False)\n",
        "        bn = nn.BatchNorm2d(out_features, affine=affine_par)\n",
        "        relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        return nn.Sequential(conv, bn, relu)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear', align_corners=True) for stage in self.stages]\n",
        "        priors.append(feats)\n",
        "        bottle = self.relu(self.bottleneck(torch.cat(priors, 1)))\n",
        "        out = self.final(bottle)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, n_classes, nInputChannels=3, classifier=\"atrous\",\n",
        "                 dilations=(2, 4), strides=(2, 2, 2, 1, 1), _print=False):\n",
        "        if _print:\n",
        "            print(\"Constructing ResNet model...\")\n",
        "            print(\"Dilations: {}\".format(dilations))\n",
        "            print(\"Number of classes: {}\".format(n_classes))\n",
        "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
        "        self.inplanes = 64\n",
        "        self.classifier = classifier\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(nInputChannels, 64, kernel_size=7, stride=strides[0], padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=strides[1], padding=1, ceil_mode=False)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=strides[2])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=strides[3], dilation__=dilations[0])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=strides[4], dilation__=dilations[1])\n",
        "\n",
        "        if classifier == \"atrous\":\n",
        "            if _print:\n",
        "                print('Initializing classifier: A-trous pyramid')\n",
        "            self.layer5 = self._make_pred_layer(ClassifierModule, [6, 12, 18, 24], [6, 12, 18, 24], n_classes=n_classes)\n",
        "        elif classifier == \"psp\":\n",
        "            if _print:\n",
        "                print('Initializing classifier: PSP')\n",
        "            self.layer5 = PSPModule(in_features=2048, out_features=512, sizes=(1, 2, 3, 6), n_classes=n_classes)\n",
        "        else:\n",
        "            self.layer5 = None\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilation__=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, affine=affine_par),\n",
        "            )\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = [block(self.inplanes, planes, stride, dilation_=dilation__, downsample=downsample)]\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, dilation_=dilation__))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_pred_layer(self, block, dilation_series, padding_series, n_classes):\n",
        "        return block(dilation_series, padding_series, n_classes)\n",
        "\n",
        "    def forward(self, x, bbox=None):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        if self.layer5 is not None:\n",
        "            x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "    def load_pretrained_ms(self, base_network, nInputChannels=3):\n",
        "        flag = 0\n",
        "        for module, module_ori in zip(self.modules(), base_network.Scale.modules()):\n",
        "            if isinstance(module, nn.Conv2d) and isinstance(module_ori, nn.Conv2d):\n",
        "                if not flag and nInputChannels != 3:\n",
        "                    module.weight[:, :3, :, :].data = deepcopy(module_ori.weight.data)\n",
        "                    module.bias = deepcopy(module_ori.bias)\n",
        "                    for i in range(3, int(module.weight.data.shape[1])):\n",
        "                        module.weight[:, i, :, :].data = deepcopy(module_ori.weight[:, -1, :, :][:, np.newaxis, :, :].data)\n",
        "                    flag = 1\n",
        "                elif module.weight.data.shape == module_ori.weight.data.shape:\n",
        "                    module.weight.data = deepcopy(module_ori.weight.data)\n",
        "                    module.bias = deepcopy(module_ori.bias)\n",
        "                else:\n",
        "                    print('Skipping Conv layer with size: {} and target size: {}'\n",
        "                          .format(module.weight.data.shape, module_ori.weight.data.shape))\n",
        "            elif isinstance(module, nn.BatchNorm2d) and isinstance(module_ori, nn.BatchNorm2d) \\\n",
        "                    and module.weight.data.shape == module_ori.weight.data.shape:\n",
        "                module.weight.data = deepcopy(module_ori.weight.data)\n",
        "                module.bias.data = deepcopy(module_ori.bias.data)\n",
        "\n",
        "\n",
        "def resnet101(n_classes, pretrained=False, nInputChannels=3, classifier=\"atrous\",\n",
        "              dilations=(2, 4), strides=(2, 2, 2, 1, 1)):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], n_classes, nInputChannels=nInputChannels,\n",
        "                   classifier=classifier, dilations=dilations, strides=strides, _print=True)\n",
        "    if pretrained:\n",
        "        model_full = Res_Deeplab(n_classes, pretrained=pretrained)\n",
        "        model.load_pretrained_ms(model_full, nInputChannels=nInputChannels)\n",
        "    return model\n",
        "\n",
        "\n",
        "class MS_Deeplab(nn.Module):\n",
        "    def __init__(self, block, NoLabels, nInputChannels=3):\n",
        "        super(MS_Deeplab, self).__init__()\n",
        "        self.Scale = ResNet(block, [3, 4, 23, 3], NoLabels, nInputChannels=nInputChannels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[2]\n",
        "        self.interp1 = nn.Upsample(size=(int(input_size*0.75)+1, int(input_size*0.75)+1), mode='bilinear', align_corners=True)\n",
        "        self.interp2 = nn.Upsample(size=(int(input_size*0.5)+1, int(input_size*0.5)+1), mode='bilinear', align_corners=True)\n",
        "        self.interp3 = nn.Upsample(size=(outS(input_size), outS(input_size)), mode='bilinear', align_corners=True)\n",
        "        out = []\n",
        "        x2 = self.interp1(x)\n",
        "        x3 = self.interp2(x)\n",
        "        out.append(self.Scale(x))  # for original scale\n",
        "        out.append(self.interp3(self.Scale(x2)))  # for 0.75x scale\n",
        "        out.append(self.Scale(x3))  # for 0.5x scale\n",
        "\n",
        "        x2Out_interp = out[1]\n",
        "        x3Out_interp = self.interp3(out[2])\n",
        "        temp1 = torch.max(out[0], x2Out_interp)\n",
        "        out.append(torch.max(temp1, x3Out_interp))\n",
        "        return out[-1]\n",
        "\n",
        "\n",
        "def Res_Deeplab(n_classes=21, pretrained=False):\n",
        "    model = MS_Deeplab(Bottleneck, n_classes)\n",
        "    if pretrained:\n",
        "        pth_model = 'MS_DeepLab_resnet_trained_VOC.pth'\n",
        "        saved_state_dict = torch.load(os.path.join(Path.models_dir(), pth_model),\n",
        "                                      map_location=lambda storage, loc: storage)\n",
        "        if n_classes != 21:\n",
        "            for i in saved_state_dict:\n",
        "                i_parts = i.split('.')\n",
        "                if i_parts[1] == 'layer5':\n",
        "                    saved_state_dict[i] = model.state_dict()[i]\n",
        "        model.load_state_dict(saved_state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_lr_params(model):\n",
        "    \"\"\"\n",
        "    This generator returns all the parameters of the net except for\n",
        "    the last classification layer. Note that for each batchnorm layer,\n",
        "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
        "    any batchnorm parameter\n",
        "    \"\"\"\n",
        "    b = [model.conv1, model.bn1, model.layer1, model.layer2, model.layer3, model.layer4, model.layer5]\n",
        "    for i in range(len(b)):\n",
        "        for k in b[i].parameters():\n",
        "            if k.requires_grad:\n",
        "                yield k\n",
        "\n",
        "\n",
        "def get_1x_lr_params(model):\n",
        "    \"\"\"\n",
        "    This generator returns all the parameters of the net except for\n",
        "    the last classification layer. Note that for each batchnorm layer,\n",
        "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
        "    any batchnorm parameter\n",
        "    \"\"\"\n",
        "    b = [model.conv1, model.bn1, model.layer1, model.layer2, model.layer3, model.layer4]\n",
        "    for i in range(len(b)):\n",
        "        for k in b[i].parameters():\n",
        "            if k.requires_grad:\n",
        "                yield k\n",
        "\n",
        "\n",
        "def get_10x_lr_params(model):\n",
        "    \"\"\"\n",
        "    This generator returns all the parameters for the last layer of the net,\n",
        "    which does the classification of pixel into classes\n",
        "    \"\"\"\n",
        "    b = [model.layer5]\n",
        "    for j in range(len(b)):\n",
        "        for k in b[j].parameters():\n",
        "            if k.requires_grad:\n",
        "                yield k\n",
        "\n",
        "\n",
        "def lr_poly(base_lr, iter_, max_iter=100, power=0.9):\n",
        "    return base_lr*((1-float(iter_)/max_iter)**power)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B17xFf6KVahC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/ExtremeNet/dextr/dataloaders/helpers.py\" \"/content/drive/My Drive/pd\""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFAJhG5bXZiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd \"/content/drive/My Drive/pd\" && python helpersaccess.py"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6mleBycYYH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "16763320-2c84-432f-d5eb-9b580b3cc2df"
      },
      "source": [
        "class Dextr(object):\n",
        "    def __init__(self, model_path='', \n",
        "                 gpu_id=0, flip_test=True):\n",
        "        if model_path == '':\n",
        "            model_path = os.path.join(\n",
        "                'cache', 'dextr_pascal-sbd.pth')\n",
        "        self.pad = 50\n",
        "        self.thres = 0.8\n",
        "        self.device = torch.device(\n",
        "            \"cuda:\"+str(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
        "        self.flip_test = flip_test\n",
        "\n",
        "        #  Create the network and load the weights\n",
        "        self.net = resnet.resnet101(1, nInputChannels=4, classifier='psp')\n",
        "        print(\"Initializing weights from: {}\".format(model_path))\n",
        "        state_dict_checkpoint = torch.load(\n",
        "          model_path, map_location=lambda storage, loc: storage)\n",
        "        # Remove the prefix .module from the model when it is trained using DataParallel\n",
        "        if 'module.' in list(state_dict_checkpoint.keys())[0]:\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in state_dict_checkpoint.items():\n",
        "                name = k[7:]  # remove `module.` from multi-gpu training\n",
        "                new_state_dict[name] = v\n",
        "        else:\n",
        "            new_state_dict = state_dict_checkpoint\n",
        "        self.net.load_state_dict(new_state_dict)\n",
        "        self.net.eval()\n",
        "        self.net.to(self.device)\n",
        "    \n",
        "    def segment(self, image, extreme_points_ori):\n",
        "        #  Crop image to the bounding box from the extreme points and resize\n",
        "        bbox = helpers.get_bbox(image, points=extreme_points_ori, pad=self.pad, zero_pad=True)\n",
        "        crop_image = helpers.crop_from_bbox(image, bbox, zero_pad=True)\n",
        "        resize_image = helpers.fixed_resize(crop_image, (512, 512)).astype(np.float32)\n",
        "\n",
        "        #  Generate extreme point heat map normalized to image values\n",
        "        extreme_points = extreme_points_ori - [np.min(extreme_points_ori[:, 0]), np.min(extreme_points_ori[:, 1])] + [self.pad,\n",
        "                                                                                                                      self.pad]\n",
        "        extreme_points = (512 * extreme_points * [1 / crop_image.shape[1], 1 / crop_image.shape[0]]).astype(np.int)\n",
        "        extreme_heatmap = helpers.make_gt(resize_image, extreme_points, sigma=10)\n",
        "        extreme_heatmap = helpers.cstm_normalize(extreme_heatmap, 255)\n",
        "\n",
        "        #  Concatenate inputs and convert to tensor\n",
        "        input_dextr = np.concatenate((resize_image, extreme_heatmap[:, :, np.newaxis]), axis=2)\n",
        "        inputs = input_dextr.transpose((2, 0, 1))[np.newaxis, ...]\n",
        "        # import pdb; pdb.set_trace()\n",
        "        if self.flip_test:\n",
        "            inputs = np.concatenate([inputs, inputs[:, :, :, ::-1]], axis=0)\n",
        "        inputs = torch.from_numpy(inputs)\n",
        "        # Run a forward pass\n",
        "        inputs = inputs.to(self.device)\n",
        "        outputs = self.net.forward(inputs)\n",
        "        outputs = upsample(outputs, size=(512, 512), mode='bilinear', align_corners=True)\n",
        "        outputs = outputs.to(torch.device('cpu'))\n",
        "        outputs = outputs.data.numpy()\n",
        "        if self.flip_test:\n",
        "            outputs = (outputs[:1] + outputs[1:, :, :, ::-1]) / 2\n",
        "\n",
        "        pred = np.transpose(outputs[0, ...], (1, 2, 0))\n",
        "        pred = 1 / (1 + np.exp(-pred))\n",
        "        pred = np.squeeze(pred)\n",
        "        result = helpers.crop2fullmask(pred, bbox, im_size=image.shape[:2], zero_pad=True, relax=self.pad) > self.thres\n",
        "        return result\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dextr = Dextr()\n",
        "    #  Read image and click the points\n",
        "    # image = np.array(Image.open('ims/dog-cat.jpg'))\n",
        "    image = np.array(Image.open(sys.argv[1]))\n",
        "    plt.ion()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    plt.title('Click the four extreme points of the objects\\nHit enter when done (do not close the window)')\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while 1:\n",
        "            extreme_points_ori = np.array(plt.ginput(4, timeout=0)).astype(np.int)\n",
        "            result = dextr.segment(image, extreme_points_ori)\n",
        "            # import pdb; pdb.set_trace()\n",
        "            results.append(result)\n",
        "            # Plot the results\n",
        "            plt.imshow(helpers.overlay_masks(image / 255, results))\n",
        "            plt.plot(extreme_points_ori[:, 0], extreme_points_ori[:, 1], 'gx')\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-4f67df431edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mdextr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDextr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;31m#  Read image and click the points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# image = np.array(Image.open('ims/dog-cat.jpg'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-4f67df431edb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, gpu_id, flip_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#  Create the network and load the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnInputChannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'psp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing weights from: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         state_dict_checkpoint = torch.load(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet101\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m    276\u001b[0m     return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n\u001b[0;32m--> 277\u001b[0;31m                    **kwargs)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'nInputChannels'"
          ]
        }
      ]
    }
  ]
}